{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d55d49-6456-4d5e-9f80-6aca6bbe1318",
   "metadata": {},
   "source": [
    "## Temporal Link Prediction in Co-Authorship Networks Using Graph Embedding Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e70926-74de-4999-9952-a9d520fad718",
   "metadata": {},
   "source": [
    "Authors: Mohammad Ghassemi (ghassem3@msu.edu), Sanaz Hasanzadeh, Soroush Ziaeinejad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019a68c7-81ab-41a8-a548-a29078e0d998",
   "metadata": {},
   "source": [
    "### Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "142f4f89-d2f6-4c23-812d-49116a776811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install dynamicgem\n",
    "import csv\n",
    "import DynamicGEM\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "from dynamicgem.embedding.dynAERNN import DynAERNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31dad40-dd68-4a5a-9b3b-e88ee9ce0e28",
   "metadata": {},
   "source": [
    "### Step 2: Import required Data and Extract Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "394d6d47-0696-4497-92fb-a0f3eead5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Link_Extraction(path):\n",
    "    \n",
    "    data_1 = [] #each row corresponds to one paper, containing names of all authors of the paper (seperated by \";\")\n",
    "    \n",
    "    with open(path, 'r', encoding=\"ISO-8859-1\") as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        for row in reader:\n",
    "            data_1.append(row[1])\n",
    "            \n",
    "        data_1[1:] #to remove the column name of dataset\n",
    "        \n",
    "    data_2 = [] #each row will be one paper's authors list, seperated by \",\"\n",
    "    \n",
    "    for i in range(len(data_1)):\n",
    "        data_2.append(data_1[i].split('; '))\n",
    "\n",
    "    authors_list = set() #each row is one author from data_2 list\n",
    "    for i in range(len(data_2)):\n",
    "        for j in range(len(data_2[i])):\n",
    "            authors_list.add(data_2[i][j])\n",
    "            \n",
    "    #authors_list.remove('')\n",
    "    \n",
    "    authors_comb = [] #each row will be all possible combinations C(data_2[i], 2) based on who published with who (edges)\n",
    "    for i in range(len(data_2)):\n",
    "        authors_comb.append(list(combinations(data_2[i], 2)))\n",
    "\n",
    "    # each row will be exactly one edge\n",
    "    links = set()\n",
    "    for i in range(len(authors_comb)):\n",
    "        for j in range(len(authors_comb[i])):\n",
    "            links.add(authors_comb[i][j])\n",
    "\n",
    "    links = list(links) \n",
    "    \n",
    "    return authors_list, links\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7881131d-1a07-4ca5-8302-c62a550eef63",
   "metadata": {},
   "source": [
    "#### Step3: Call \"Link_Extraction\" function on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1024cd1d-bd34-4c97-bab4-68cd3ab38f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_list_2015, links_2015 = Link_Extraction('data/CSV/REPORTER_PUB_C_2015.csv')\n",
    "\n",
    "authors_list_2016, links_2016 = Link_Extraction('data/CSV/REPORTER_PUB_C_2016.csv')\n",
    "\n",
    "authors_list_2017, links_2017 = Link_Extraction('data/CSV/REPORTER_PUB_C_2017.csv')\n",
    "\n",
    "authors_list_2018, links_2018 = Link_Extraction('data/CSV/REPORTER_PUB_C_2018.csv')\n",
    "\n",
    "authors_list_2019, links_2019 = Link_Extraction('data/CSV/REPORTER_PUB_C_2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e13ff2c-380d-4980-8445-42ae28e2f3b3",
   "metadata": {},
   "source": [
    "#### 4- Intersection of all Years' Author-Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2013a34-b2c7-442f-b0ef-d58b0d28ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_intersect = list(set.intersection(authors_list_2015, authors_list_2016, authors_list_2017, authors_list_2018, authors_list_2019))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b7e2c-29c7-4859-9f20-b6ce25e2a2c1",
   "metadata": {},
   "source": [
    "#### 5- Generate Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99a74642-bedc-476a-80c7-f841efc0a33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Graph_Generate(links, authors_intersect):\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    all_links = filter(lambda c: c[0] in authors_intersect and c[1] in authors_intersect, links)\n",
    "    list_all_links = list(all_links)\n",
    "    #print(\"Num of Links: %float\" %len(list_all_links))\n",
    "    \n",
    "    for i in range(len(list_all_links)):\n",
    "        G.add_edge(list_all_links[i][0], list_all_links[i][1])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce51d6d-bdcd-4b82-9031-a081a7cb0d39",
   "metadata": {},
   "source": [
    "#### 6- Call Graph_Generate Function for each Year, Save Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f3fa04-fac3-4d60-afe0-99fe665304ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_2015 = Graph_Generate(links_2015, authors_intersect)\n",
    "#print('2015 Graph is Generated')\n",
    "G_2016 = Graph_Generate(links_2016, authors_intersect)\n",
    "#print('2016 Graph is Generated')\n",
    "G_2017 = Graph_Generate(links_2017, authors_intersect)\n",
    "#print('2017 Graph is Generated')\n",
    "G_2018 = Graph_Generate(links_2018, authors_intersect)\n",
    "#print('2018 Graph is Generated')\n",
    "G_2019 = Graph_Generate(links_2019, authors_intersect)\n",
    "#print('2019 Graph is Generated')\n",
    "\n",
    "nx.write_pajek(G_2015, \"/data/Graphs/G-2015.net\")\n",
    "nx.write_pajek(G_2016, \"/data/Graphs/G-2016.net\")\n",
    "nx.write_pajek(G_2017, \"/data/Graphs/G-2017.net\")\n",
    "nx.write_pajek(G_2018, \"/data/Graphs/G-2018.net\")\n",
    "nx.write_pajek(G_2019, \"/data/Graphs/G-2019.net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b532ed4-c2f5-4218-b685-0c4c219ef52d",
   "metadata": {},
   "source": [
    "#### 7- Temporal Embedding\n",
    "Output is a npy array: (4, 62641, 128)\n",
    "first matrix is embeding for 2016 based on 2015\n",
    "second one is embeding for 2017 based on 2016 and 2015\n",
    "third one is embeding for 2018 based on 2017, 2016, and 2015\n",
    "fourth one is embeding for 2019 based on 2018, 2017, 2016, and 2015\n",
    "\n",
    "For any series of graphs the output will be in shape of (number of graphs-1, number of nodes, embedding dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7690adae-13c7-413f-a328-f7e500bc5884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pickle5 as pickle\n",
    "from dynamicgem.embedding.dynAERNN import DynAERNN\n",
    "\n",
    "# Set Variables\n",
    "dim_emb = 128\n",
    "lookback = 1\n",
    "batchNumber = 200\n",
    "graphPath = '../data/Graphs/'\n",
    "\n",
    "# To have sorted embedding in the Output\n",
    "def node_sorter(graph):\n",
    "    H = nx.Graph()\n",
    "    new_nodes = sorted(graph.nodes(data=True))\n",
    "    H.add_nodes_from(new_nodes)\n",
    "    H.add_edges_from(graph.edges(data=True))\n",
    "    return H\n",
    "\n",
    "graphlist = sorted(glob.glob(f'{graphPath}/*.net'))\n",
    "graphs = []\n",
    "for i in graphlist:\n",
    "    graphs.append(node_sorter(pickle.load(open(i, \"rb\"))))\n",
    "\n",
    "length = len(graphs)\n",
    "embedding = DynAERNN(d=dim_emb,\n",
    "                     beta=5,\n",
    "                     n_prev_graphs=lookback,\n",
    "                     nu1=1e-6,\n",
    "                     nu2=1e-6,\n",
    "                     n_aeunits=[500, 300],\n",
    "                     n_lstmunits=[500, dim_emb],\n",
    "                     rho=0.3,\n",
    "                     n_iter=25,\n",
    "                     xeta=1e-3,\n",
    "                     n_batch=batchNumber,\n",
    "                     modelfile=['enc_model_dynAERNN.json',\n",
    "                                'GEL/dec_model_dynAERNN.json'],\n",
    "                     weightfile=['GEL/enc_weights_dynAERNN.hdf5',\n",
    "                                 'GEL/dec_weights_dynAERNN.hdf5'],\n",
    "                     savefilesuffix=\"testing\")\n",
    "\n",
    "embs = []\n",
    "t1 = time.clock()\n",
    "for temp_var in range(lookback + 1, length + 1):\n",
    "    emb, _ = embedding.learn_embeddings(graphs[:temp_var])\n",
    "    print('emb type: ', type(emb))\n",
    "    embs.append(emb)\n",
    "embs = np.asarray(embs)\n",
    "e = embs.round(decimals=3)\n",
    "\n",
    "print('embs shape: ', embs)\n",
    "print(embedding._method_name + ':\\n\\tTraining time: %f' % (time.clock() - t1))\n",
    "np.save(f'{graphPath}/embeddeds_dim{dim_emb}_batchNumber{batchNumber}_length{length}_lookback{lookback}.npy', embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1adf8cc-cbd7-4cd3-bb07-b39cf0f1d4da",
   "metadata": {},
   "source": [
    "### Working with Embedded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "800c499f-2320-4afb-b18b-3051c415f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pickle5 as pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234961d4-008d-42c9-b861-922e3891e771",
   "metadata": {},
   "source": [
    "### 1- Load embedded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c35a060c-0a39-48dd-91c4-3625d1dc211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load('data/EMBEDDING/embeddeds_dim128_batchNumber200_length5_lookback1.npy')\n",
    "\n",
    "# We will predict 2019 collaborations based on 2018 and 2017 (these data is based on previous years, so prediction is based on\n",
    "# all previous years 2015, 2016, 2017, and 2018)\n",
    "embed2018 = embeddings[2]\n",
    "embed2017 = embeddings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10f9ad9c-dcae-4800-b1a3-64b9c8853365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To have sorted embedding in Output\n",
    "def node_sorter(graph):\n",
    "    H = nx.Graph()\n",
    "    new_nodes = sorted(graph.nodes(data=True))\n",
    "    H.add_nodes_from(new_nodes)\n",
    "    H.add_edges_from(graph.edges(data=True))\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "917cf48e-d68b-419d-94e8-a7f56d54a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes in all these graphs are their intersection, so nose_set is the same for all years\n",
    "\n",
    "graph_2019 = nx.read_pajek('data/Graphs/pajek_graph19.net')\n",
    "SortedNodeG2019 = node_sorter(graph_2019)\n",
    "node_emb_dict_2018 = {list(SortedNodeG2019.nodes())[i] : embed2018[i] for i in range(len(SortedNodeG2019.nodes()))}\n",
    "node_emb_dict_2017 = {list(SortedNodeG2019.nodes())[i] : embed2017[i] for i in range(len(SortedNodeG2019.nodes()))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f34730f-9770-4870-8525-5fd9d0ab4b58",
   "metadata": {},
   "source": [
    "### 2- Generate Train/ Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0493854b-5245-4d5f-b862-25eea1a124bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of negative samples is 4 times positive samples\n",
    "\n",
    "num_pos_samp = len(SortedNodeG2019.edges())\n",
    "num_neg_samp = 4*num_pos_samp\n",
    "\n",
    "nodeList = list(SortedNodeG2019.nodes())\n",
    "\n",
    "neg_set = []\n",
    "while len(neg_set) < num_neg_samp:\n",
    "    \n",
    "    first = random.randint(0, len(SortedNodeG2019.nodes())-1)\n",
    "    second = random.randint(0, len(SortedNodeG2019.nodes())-1)\n",
    "\n",
    "    f = nodeList[first]\n",
    "    s = nodeList[second]\n",
    "                            \n",
    "    if SortedNodeG2019.has_edge(f, s) == False:\n",
    "        neg_set.append((f, s))\n",
    "        \n",
    "edgeList = list(SortedNodeG2019.edges())\n",
    "\n",
    "# generate train/test data for baseline\n",
    "pos_samp = []\n",
    "for i in range(len(edgeList)):\n",
    "    temp = []\n",
    "    f = edgeList[i][0]\n",
    "    s = edgeList[i][1]\n",
    "    temp.append(f)\n",
    "    temp.append(s)\n",
    "    temp.append(node_emb_dict_2018[f])\n",
    "    temp.append(node_emb_dict_2018[s])\n",
    "    temp.append(1)\n",
    "    pos_samp.append(temp)\n",
    "    \n",
    "neg_samp = []\n",
    "for i in range(len(neg_set)):\n",
    "    temp = []\n",
    "    f = neg_set[i][0]\n",
    "    s = neg_set[i][1]\n",
    "    temp.append(f)\n",
    "    temp.append(s)\n",
    "    temp.append(node_emb_dict_2018[f])\n",
    "    temp.append(node_emb_dict_2018[s])\n",
    "    temp.append(-1)\n",
    "    neg_samp.append(temp)   \n",
    "    \n",
    "# positive and negative samples in a unified list\n",
    "samp = []\n",
    "for i in pos_samp:\n",
    "  samp.append(i)\n",
    "for i in neg_samp:\n",
    "  samp.append(i)    \n",
    "\n",
    "shuf_samp = random.sample(samp, len(samp))\n",
    "x = []\n",
    "y = []\n",
    "for i in range(len(shuf_samp)):\n",
    "    x.append(np.concatenate((shuf_samp[i][2], shuf_samp[i][3]), axis=None))\n",
    "    y.append(shuf_samp[i][4])\n",
    "    \n",
    "loc_xtrain, loc_xtest, loc_ytrain, loc_ytest = train_test_split(x, y, \n",
    "                                                test_size = 0.3, \n",
    "                                                random_state = 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1ed8d91-9ba1-480c-a1ae-69e04c0affb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate train/test data for velocity\n",
    "\n",
    "vel_pos_samp = []\n",
    "for i in range(len(edgeList)):\n",
    "    temp = []\n",
    "    f = edgeList[i][0]\n",
    "    s = edgeList[i][1]\n",
    "    temp.append(f)\n",
    "    temp.append(s)\n",
    "    temp.append(2*node_emb_dict_2018[f]-node_emb_dict_2017[f])\n",
    "    temp.append(2*node_emb_dict_2018[s]-node_emb_dict_2017[s])\n",
    "    temp.append(1)\n",
    "    vel_pos_samp.append(temp)\n",
    "               \n",
    "vel_neg_samp = []\n",
    "for i in range(len(neg_set)):\n",
    "    temp = []\n",
    "    f = neg_set[i][0]\n",
    "    s = neg_set[i][1]\n",
    "    temp.append(f)\n",
    "    temp.append(s)\n",
    "    temp.append(2*node_emb_dict_2018[f]-node_emb_dict_2017[f])\n",
    "    temp.append(2*node_emb_dict_2018[s]-node_emb_dict_2017[s])\n",
    "    temp.append(-1)\n",
    "    vel_neg_samp.append(temp)  \n",
    "    \n",
    "vel_samp = []\n",
    "for i in vel_pos_samp:\n",
    "  vel_samp.append(i)\n",
    "for i in vel_neg_samp:\n",
    "  vel_samp.append(i)\n",
    "\n",
    "vel_shuf_samp = random.sample(vel_samp, len(vel_samp))\n",
    "vel_x = []\n",
    "vel_y = []\n",
    "for i in range(len(vel_shuf_samp)):\n",
    "    vel_x.append(np.concatenate((vel_shuf_samp[i][2], vel_shuf_samp[i][3]), axis=None))    \n",
    "    vel_y.append(vel_shuf_samp[i][4])\n",
    "    \n",
    "vel_xtrain, vel_xtest, vel_ytrain, vel_ytest = train_test_split(vel_x, vel_y, \n",
    "                                                test_size = 0.3, \n",
    "                                                random_state = 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacbd831-c620-4e9f-b848-1bb2076ba37d",
   "metadata": {},
   "source": [
    "### 3- Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f2368ad-1ff5-461c-8c3f-b3d7d8f55328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline\n",
      "0.6457894839470578\n",
      "velocity\n",
      "0.6963615936343718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "modelb = MLPClassifier(alpha=1, max_iter=1000)\n",
    "modelb.fit(loc_xtrain, loc_ytrain)\n",
    "ybase = modelb.predict(loc_xtest)\n",
    "modelv = MLPClassifier(alpha=1, max_iter=1000)\n",
    "modelv.fit(vel_xtrain, vel_ytrain)\n",
    "yvel = modelv.predict(vel_xtest)\n",
    "\n",
    "print(\"baseline\")\n",
    "print(sklearn.metrics.roc_auc_score(loc_ytest, ybase))\n",
    "\n",
    "print(\"velocity\")\n",
    "print(sklearn.metrics.roc_auc_score(vel_ytest, yvel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eeb3dae-bfe8-4f36-a115-fec6036cef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed2016 = embeddings[0]\n",
    "node_emb_dict_2016 = {list(SortedNodeG2019.nodes())[i] : embed2016[i] for i in range(len(SortedNodeG2019.nodes()))}\n",
    "\n",
    "# generate train/test data for acceleration\n",
    "\n",
    "acc_pos_samp = []\n",
    "for i in range(len(edgeList)):\n",
    "    temp = []\n",
    "    f = edgeList[i][0]\n",
    "    s = edgeList[i][1]\n",
    "    temp.append(f)\n",
    "    temp.append(s)\n",
    "    temp.append(2.25*node_emb_dict_2018[f]-1.5*node_emb_dict_2017[f]-0.25*node_emb_dict_2016[f])\n",
    "    temp.append(2.25*node_emb_dict_2018[s]-1.5*node_emb_dict_2017[s]-0.25*node_emb_dict_2016[s])\n",
    "    temp.append(1)\n",
    "    acc_pos_samp.append(temp)\n",
    "               \n",
    "acc_neg_samp = []\n",
    "for i in range(len(neg_set)):\n",
    "    temp = []\n",
    "    f = neg_set[i][0]\n",
    "    s = neg_set[i][1]\n",
    "    temp.append(f)\n",
    "    temp.append(s)\n",
    "    temp.append(2.25*node_emb_dict_2018[f]-1.5*node_emb_dict_2017[f]-0.25*node_emb_dict_2016[f])\n",
    "    temp.append(2.25*node_emb_dict_2018[s]-1.5*node_emb_dict_2017[s]-0.25*node_emb_dict_2016[s])\n",
    "    temp.append(-1)\n",
    "    acc_neg_samp.append(temp)  \n",
    "    \n",
    "acc_samp = []\n",
    "for i in acc_pos_samp:\n",
    "  acc_samp.append(i)\n",
    "for i in acc_neg_samp:\n",
    "  acc_samp.append(i)\n",
    "\n",
    "acc_shuf_samp = random.sample(acc_samp, len(acc_samp))\n",
    "acc_x = []\n",
    "acc_y = []\n",
    "for i in range(len(acc_shuf_samp)):\n",
    "    acc_x.append(np.concatenate((acc_shuf_samp[i][2], acc_shuf_samp[i][3]), axis=None))    \n",
    "    acc_y.append(acc_shuf_samp[i][4])\n",
    "    \n",
    "acc_xtrain, acc_xtest, acc_ytrain, acc_ytest = train_test_split(acc_x, acc_y, \n",
    "                                                test_size = 0.3, \n",
    "                                                random_state = 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55ae8412-69e2-4b12-924e-1b79fd091a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceleration\n",
      "0.6711056226888197\n"
     ]
    }
   ],
   "source": [
    "model_acc = MLPClassifier(alpha=1, max_iter=1000)\n",
    "model_acc.fit(acc_xtrain, acc_ytrain)\n",
    "y_acc = modelb.predict(acc_xtest)\n",
    "\n",
    "print(\"acceleration\")\n",
    "print(sklearn.metrics.roc_auc_score(acc_ytest, y_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6664b7-65a0-4ae5-a2b3-dc1c078e4f41",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'edgeList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a071dcee051e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medgeList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medgeList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medgeList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'edgeList' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "x_acc = []\n",
    "y_acc = []\n",
    "for i in range(len(edgeList)):\n",
    "    f = edgeList[i][0]\n",
    "    s = edgeList[i][1]\n",
    "    x_acc.append(2.25*node_emb_dict_2018[f]-1.5*node_emb_dict_2017[f]-0.25*node_emb_dict_2016[f])\n",
    "    y_acc.append(2.25*node_emb_dict_2018[s]-1.5*node_emb_dict_2017[s]-0.25*node_emb_dict_2016[s])\n",
    "               \n",
    "acc_neg_samp = []\n",
    "for i in range(len(neg_set)):\n",
    "    f = neg_set[i][0]\n",
    "    s = neg_set[i][1]\n",
    "    x_acc.append(2.25*node_emb_dict_2018[f]-1.5*node_emb_dict_2017[f]-0.25*node_emb_dict_2016[f])\n",
    "    y_acc.append(2.25*node_emb_dict_2018[s]-1.5*node_emb_dict_2017[s]-0.25*node_emb_dict_2016[s]) \n",
    "\n",
    "acc_Similarities = cosine_similarity(x_acc, y_acc, dense_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd7d0fb7-de0d-4647-98b8-ce6d763ba7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed2016 = embeddings[0]\n",
    "node_emb_dict_2016 = {list(SortedNodeG2019.nodes())[i] : embed2016[i] for i in range(len(SortedNodeG2019.nodes()))}\n",
    "\n",
    "num_node = len(nodeList)\n",
    "\n",
    "vel_loc_2019 = []\n",
    "acc_loc_2019 = []\n",
    "\n",
    "for i in range(num_node):\n",
    "    node_name = nodeList[i]\n",
    "    vel_loc_2019.append(2*node_emb_dict_2018[node_name]-node_emb_dict_2017[node_name])\n",
    "    acc_loc_2019.append(2.25*node_emb_dict_2018[node_name]-1.5*node_emb_dict_2017[node_name]-0.25*node_emb_dict_2016[node_name])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97599968-c198-4b0c-801e-b6cb39d9602c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-a6e6236a654d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0macc_cosine_similarity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstart1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstart2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         sklearn.metrics.pairwise.cosine_similarity(acc_loc_2019[start1: start1 + batch_size], \\\n\u001b[0m\u001b[1;32m     16\u001b[0m                                                    \u001b[0macc_loc_2019\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstart2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                           dense_output=True)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    147\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                         estimator=estimator)\n\u001b[0;32m--> 149\u001b[0;31m         Y = check_array(Y, accept_sparse=accept_sparse, dtype=dtype,\n\u001b[0m\u001b[1;32m    150\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                         estimator=estimator)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    638\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy\n",
    "\n",
    "total_size = num_node\n",
    "batch_size = 10\n",
    "batch_num = math.ceil(total_size/batch_size)\n",
    "start1 = 0\n",
    "start2 = 0\n",
    "\n",
    "acc_cosine_similarity = [[0 for x in range(num_node)] for y in range(num_node)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8938cf32-172d-436c-8035-065540da2434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "2070\n",
      "2080\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "2150\n",
      "2160\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "2200\n",
      "2210\n",
      "2220\n",
      "2230\n",
      "2240\n",
      "2250\n",
      "2260\n",
      "2270\n",
      "2280\n",
      "2290\n",
      "2300\n",
      "2310\n",
      "2320\n",
      "2330\n",
      "2340\n",
      "2350\n",
      "2360\n",
      "2370\n",
      "2380\n",
      "2390\n",
      "2400\n",
      "2410\n",
      "2420\n",
      "2430\n",
      "2440\n",
      "2450\n",
      "2460\n",
      "2470\n",
      "2480\n",
      "2490\n",
      "2500\n",
      "2510\n",
      "2520\n",
      "2530\n",
      "2540\n",
      "2550\n",
      "2560\n",
      "2570\n",
      "2580\n",
      "2590\n",
      "2600\n",
      "2610\n",
      "2620\n",
      "2630\n",
      "2640\n",
      "2650\n",
      "2660\n",
      "2670\n",
      "2680\n",
      "2690\n",
      "2700\n",
      "2710\n",
      "2720\n",
      "2730\n",
      "2740\n",
      "2750\n",
      "2760\n",
      "2770\n",
      "2780\n",
      "2790\n",
      "2800\n",
      "2810\n",
      "2820\n",
      "2830\n",
      "2840\n",
      "2850\n",
      "2860\n",
      "2870\n",
      "2880\n",
      "2890\n",
      "2900\n",
      "2910\n",
      "2920\n",
      "2930\n",
      "2940\n",
      "2950\n",
      "2960\n",
      "2970\n",
      "2980\n",
      "2990\n",
      "3000\n",
      "3010\n",
      "3020\n",
      "3030\n",
      "3040\n",
      "3050\n",
      "3060\n",
      "3070\n",
      "3080\n",
      "3090\n",
      "3100\n",
      "3110\n",
      "3120\n",
      "3130\n",
      "3140\n",
      "3150\n",
      "3160\n",
      "3170\n",
      "3180\n",
      "3190\n",
      "3200\n",
      "3210\n",
      "3220\n",
      "3230\n",
      "3240\n",
      "3250\n",
      "3260\n",
      "3270\n",
      "3280\n",
      "3290\n",
      "3300\n",
      "3310\n",
      "3320\n",
      "3330\n",
      "3340\n",
      "3350\n",
      "3360\n",
      "3370\n",
      "3380\n",
      "3390\n",
      "3400\n",
      "3410\n",
      "3420\n",
      "3430\n",
      "3440\n",
      "3450\n",
      "3460\n",
      "3470\n",
      "3480\n",
      "3490\n",
      "3500\n",
      "3510\n",
      "3520\n",
      "3530\n",
      "3540\n",
      "3550\n",
      "3560\n",
      "3570\n",
      "3580\n",
      "3590\n",
      "3600\n",
      "3610\n",
      "3620\n",
      "3630\n",
      "3640\n",
      "3650\n",
      "3660\n",
      "3670\n",
      "3680\n",
      "3690\n",
      "3700\n",
      "3710\n",
      "3720\n",
      "3730\n",
      "3740\n",
      "3750\n",
      "3760\n",
      "3770\n",
      "3780\n",
      "3790\n",
      "3800\n",
      "3810\n",
      "3820\n",
      "3830\n",
      "3840\n",
      "3850\n",
      "3860\n",
      "3870\n",
      "3880\n",
      "3890\n",
      "3900\n",
      "3910\n",
      "3920\n",
      "3930\n",
      "3940\n",
      "3950\n",
      "3960\n",
      "3970\n",
      "3980\n",
      "3990\n",
      "4000\n",
      "4010\n",
      "4020\n",
      "4030\n",
      "4040\n",
      "4050\n",
      "4060\n",
      "4070\n",
      "4080\n",
      "4090\n",
      "4100\n",
      "4110\n",
      "4120\n",
      "4130\n",
      "4140\n",
      "4150\n",
      "4160\n",
      "4170\n",
      "4180\n",
      "4190\n",
      "4200\n",
      "4210\n",
      "4220\n",
      "4230\n",
      "4240\n",
      "4250\n",
      "4260\n",
      "4270\n",
      "4280\n",
      "4290\n",
      "4300\n",
      "4310\n",
      "4320\n",
      "4330\n",
      "4340\n",
      "4350\n",
      "4360\n",
      "4370\n",
      "4380\n",
      "4390\n",
      "4400\n",
      "4410\n",
      "4420\n",
      "4430\n",
      "4440\n",
      "4450\n",
      "4460\n",
      "4470\n",
      "4480\n",
      "4490\n",
      "4500\n",
      "4510\n",
      "4520\n",
      "4530\n",
      "4540\n",
      "4550\n",
      "4560\n",
      "4570\n",
      "4580\n",
      "4590\n",
      "4600\n",
      "4610\n",
      "4620\n",
      "4630\n",
      "4640\n",
      "4650\n",
      "4660\n",
      "4670\n",
      "4680\n",
      "4690\n",
      "4700\n",
      "4710\n",
      "4720\n",
      "4730\n",
      "4740\n",
      "4750\n",
      "4760\n",
      "4770\n",
      "4780\n",
      "4790\n",
      "4800\n",
      "4810\n",
      "4820\n",
      "4830\n",
      "4840\n",
      "4850\n",
      "4860\n",
      "4870\n",
      "4880\n",
      "4890\n",
      "4900\n",
      "4910\n",
      "4920\n",
      "4930\n",
      "4940\n",
      "4950\n",
      "4960\n",
      "4970\n",
      "4980\n",
      "4990\n",
      "5000\n",
      "5010\n",
      "5020\n",
      "5030\n",
      "5040\n",
      "5050\n",
      "5060\n",
      "5070\n",
      "5080\n",
      "5090\n",
      "5100\n",
      "5110\n",
      "5120\n",
      "5130\n",
      "5140\n",
      "5150\n",
      "5160\n",
      "5170\n",
      "5180\n",
      "5190\n",
      "5200\n",
      "5210\n",
      "5220\n",
      "5230\n",
      "5240\n",
      "5250\n",
      "5260\n",
      "5270\n",
      "5280\n",
      "5290\n",
      "5300\n",
      "5310\n",
      "5320\n",
      "5330\n",
      "5340\n",
      "5350\n",
      "5360\n",
      "5370\n",
      "5380\n",
      "5390\n",
      "5400\n",
      "5410\n",
      "5420\n",
      "5430\n",
      "5440\n",
      "5450\n",
      "5460\n",
      "5470\n",
      "5480\n",
      "5490\n",
      "5500\n",
      "5510\n",
      "5520\n",
      "5530\n",
      "5540\n",
      "5550\n",
      "5560\n",
      "5570\n",
      "5580\n",
      "5590\n",
      "5600\n",
      "5610\n",
      "5620\n",
      "5630\n",
      "5640\n",
      "5650\n",
      "5660\n",
      "5670\n",
      "5680\n",
      "5690\n",
      "5700\n",
      "5710\n",
      "5720\n",
      "5730\n",
      "5740\n",
      "5750\n",
      "5760\n",
      "5770\n",
      "5780\n",
      "5790\n",
      "5800\n",
      "5810\n",
      "5820\n",
      "5830\n",
      "5840\n",
      "5850\n",
      "5860\n",
      "5870\n",
      "5880\n",
      "5890\n",
      "5900\n",
      "5910\n",
      "5920\n",
      "5930\n",
      "5940\n",
      "5950\n",
      "5960\n",
      "5970\n",
      "5980\n",
      "5990\n",
      "6000\n",
      "6010\n",
      "6020\n",
      "6030\n",
      "6040\n",
      "6050\n",
      "6060\n",
      "6070\n",
      "6080\n",
      "6090\n",
      "6100\n",
      "6110\n",
      "6120\n",
      "6130\n",
      "6140\n",
      "6150\n",
      "6160\n",
      "6170\n",
      "6180\n",
      "6190\n",
      "6200\n",
      "6210\n",
      "6220\n",
      "6230\n",
      "6240\n",
      "6250\n",
      "6260\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "acc_loc_2019 = np.asarray(acc_loc_2019, dtype=np.float32)\n",
    "\n",
    "start1 = 0\n",
    "start2 = 0\n",
    "\n",
    "for i in range(batch_num):\n",
    "    for j in range(batch_num):\n",
    "        acc_cosine_similarity[start1: start1 + batch_size][start2: start2 + batch_size] = \\\n",
    "        cosine_similarity(acc_loc_2019[start1: start1 + batch_size], \\\n",
    "                                                   acc_loc_2019[start2: start2 + batch_size], \\\n",
    "                          dense_output=True)\n",
    "        start2 = (j+1)*batch_size\n",
    "    start1 = (i+1)*batch_size\n",
    "    start2 = 0\n",
    "    if(i%10 == 0):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b401f2b-9f60-44b2-9f51-53d815068f08",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-204c0ab1dd2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0macc_cosine_sim_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"acc_sim.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0macc_cosine_similarity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_cosine_sim_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0macc_cosine_sim_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[1;32m   1427\u001b[0m                                     \u001b[0;34m\"format specifier ('%s')\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m                                     % (str(X.dtype), format))\n\u001b[0;32m-> 1429\u001b[0;31m                 \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfooter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mwrite_normal\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mwrite_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masunicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc_cosine_sim_file = open(\"acc_sim.txt\", \"w\")\n",
    "for row in acc_cosine_similarity:\n",
    "    np.savetxt(acc_cosine_sim_file, row)\n",
    "\n",
    "acc_cosine_sim_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9e466307-98e9-4f1f-b0e7-f5b207d858ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = num_node\n",
    "batch_size = 10\n",
    "batch_num = math.ceil(total_size/batch_size)\n",
    "start = 0\n",
    "\n",
    "acc_loc_2019 = np.array(acc_loc_2019)\n",
    "batches = []\n",
    "for i in range(batch_num):\n",
    "    batches.append(acc_loc_2019[start: start+batch_size])\n",
    "    start = start+batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "05ffeb89-cfb2-4045-b614-c0bb46956e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "2070\n",
      "2080\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "2150\n",
      "2160\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "2200\n",
      "2210\n",
      "2220\n",
      "2230\n",
      "2240\n",
      "2250\n",
      "2260\n",
      "2270\n",
      "2280\n",
      "2290\n",
      "2300\n",
      "2310\n",
      "2320\n",
      "2330\n",
      "2340\n",
      "2350\n",
      "2360\n",
      "2370\n",
      "2380\n",
      "2390\n",
      "2400\n",
      "2410\n",
      "2420\n",
      "2430\n",
      "2440\n",
      "2450\n",
      "2460\n",
      "2470\n",
      "2480\n",
      "2490\n",
      "2500\n",
      "2510\n",
      "2520\n",
      "2530\n",
      "2540\n",
      "2550\n",
      "2560\n",
      "2570\n",
      "2580\n",
      "2590\n",
      "2600\n",
      "2610\n",
      "2620\n",
      "2630\n",
      "2640\n",
      "2650\n",
      "2660\n",
      "2670\n",
      "2680\n",
      "2690\n",
      "2700\n",
      "2710\n",
      "2720\n",
      "2730\n",
      "2740\n",
      "2750\n",
      "2760\n",
      "2770\n",
      "2780\n",
      "2790\n",
      "2800\n",
      "2810\n",
      "2820\n",
      "2830\n",
      "2840\n",
      "2850\n",
      "2860\n",
      "2870\n",
      "2880\n",
      "2890\n",
      "2900\n",
      "2910\n",
      "2920\n",
      "2930\n",
      "2940\n",
      "2950\n",
      "2960\n",
      "2970\n",
      "2980\n",
      "2990\n",
      "3000\n",
      "3010\n",
      "3020\n",
      "3030\n",
      "3040\n",
      "3050\n",
      "3060\n",
      "3070\n",
      "3080\n",
      "3090\n",
      "3100\n",
      "3110\n",
      "3120\n",
      "3130\n",
      "3140\n",
      "3150\n",
      "3160\n",
      "3170\n",
      "3180\n",
      "3190\n",
      "3200\n",
      "3210\n",
      "3220\n",
      "3230\n",
      "3240\n",
      "3250\n",
      "3260\n",
      "3270\n",
      "3280\n",
      "3290\n",
      "3300\n",
      "3310\n",
      "3320\n",
      "3330\n",
      "3340\n",
      "3350\n",
      "3360\n",
      "3370\n",
      "3380\n",
      "3390\n",
      "3400\n",
      "3410\n",
      "3420\n",
      "3430\n",
      "3440\n",
      "3450\n",
      "3460\n",
      "3470\n",
      "3480\n",
      "3490\n",
      "3500\n",
      "3510\n",
      "3520\n",
      "3530\n",
      "3540\n",
      "3550\n",
      "3560\n",
      "3570\n",
      "3580\n",
      "3590\n",
      "3600\n",
      "3610\n",
      "3620\n",
      "3630\n",
      "3640\n",
      "3650\n",
      "3660\n",
      "3670\n",
      "3680\n",
      "3690\n",
      "3700\n",
      "3710\n",
      "3720\n",
      "3730\n",
      "3740\n",
      "3750\n",
      "3760\n",
      "3770\n",
      "3780\n",
      "3790\n",
      "3800\n",
      "3810\n",
      "3820\n",
      "3830\n",
      "3840\n",
      "3850\n",
      "3860\n",
      "3870\n",
      "3880\n",
      "3890\n",
      "3900\n",
      "3910\n",
      "3920\n",
      "3930\n",
      "3940\n",
      "3950\n",
      "3960\n",
      "3970\n",
      "3980\n",
      "3990\n",
      "4000\n",
      "4010\n",
      "4020\n",
      "4030\n",
      "4040\n",
      "4050\n",
      "4060\n",
      "4070\n",
      "4080\n",
      "4090\n",
      "4100\n",
      "4110\n",
      "4120\n",
      "4130\n",
      "4140\n",
      "4150\n",
      "4160\n",
      "4170\n",
      "4180\n",
      "4190\n",
      "4200\n",
      "4210\n",
      "4220\n",
      "4230\n",
      "4240\n",
      "4250\n",
      "4260\n",
      "4270\n",
      "4280\n",
      "4290\n",
      "4300\n",
      "4310\n",
      "4320\n",
      "4330\n",
      "4340\n",
      "4350\n",
      "4360\n",
      "4370\n",
      "4380\n",
      "4390\n",
      "4400\n",
      "4410\n",
      "4420\n",
      "4430\n",
      "4440\n",
      "4450\n",
      "4460\n",
      "4470\n",
      "4480\n",
      "4490\n",
      "4500\n",
      "4510\n",
      "4520\n",
      "4530\n",
      "4540\n",
      "4550\n",
      "4560\n",
      "4570\n",
      "4580\n",
      "4590\n",
      "4600\n",
      "4610\n",
      "4620\n",
      "4630\n",
      "4640\n",
      "4650\n",
      "4660\n",
      "4670\n",
      "4680\n",
      "4690\n",
      "4700\n",
      "4710\n",
      "4720\n",
      "4730\n",
      "4740\n",
      "4750\n",
      "4760\n",
      "4770\n",
      "4780\n",
      "4790\n",
      "4800\n",
      "4810\n",
      "4820\n",
      "4830\n",
      "4840\n",
      "4850\n",
      "4860\n",
      "4870\n",
      "4880\n",
      "4890\n",
      "4900\n",
      "4910\n",
      "4920\n",
      "4930\n",
      "4940\n",
      "4950\n",
      "4960\n",
      "4970\n",
      "4980\n",
      "4990\n",
      "5000\n",
      "5010\n",
      "5020\n",
      "5030\n",
      "5040\n",
      "5050\n",
      "5060\n",
      "5070\n",
      "5080\n",
      "5090\n",
      "5100\n",
      "5110\n",
      "5120\n",
      "5130\n",
      "5140\n",
      "5150\n",
      "5160\n",
      "5170\n",
      "5180\n",
      "5190\n",
      "5200\n",
      "5210\n",
      "5220\n",
      "5230\n",
      "5240\n",
      "5250\n",
      "5260\n",
      "5270\n",
      "5280\n",
      "5290\n",
      "5300\n",
      "5310\n",
      "5320\n",
      "5330\n",
      "5340\n",
      "5350\n",
      "5360\n",
      "5370\n",
      "5380\n",
      "5390\n",
      "5400\n",
      "5410\n",
      "5420\n",
      "5430\n",
      "5440\n",
      "5450\n",
      "5460\n",
      "5470\n",
      "5480\n",
      "5490\n",
      "5500\n",
      "5510\n",
      "5520\n",
      "5530\n",
      "5540\n",
      "5550\n",
      "5560\n",
      "5570\n",
      "5580\n",
      "5590\n",
      "5600\n",
      "5610\n",
      "5620\n",
      "5630\n",
      "5640\n",
      "5650\n",
      "5660\n",
      "5670\n",
      "5680\n",
      "5690\n",
      "5700\n",
      "5710\n",
      "5720\n",
      "5730\n",
      "5740\n",
      "5750\n",
      "5760\n",
      "5770\n",
      "5780\n",
      "5790\n",
      "5800\n",
      "5810\n",
      "5820\n",
      "5830\n",
      "5840\n",
      "5850\n",
      "5860\n",
      "5870\n",
      "5880\n",
      "5890\n",
      "5900\n",
      "5910\n",
      "5920\n",
      "5930\n",
      "5940\n",
      "5950\n",
      "5960\n",
      "5970\n",
      "5980\n",
      "5990\n",
      "6000\n",
      "6010\n",
      "6020\n",
      "6030\n",
      "6040\n",
      "6050\n",
      "6060\n",
      "6070\n",
      "6080\n",
      "6090\n",
      "6100\n",
      "6110\n",
      "6120\n",
      "6130\n",
      "6140\n",
      "6150\n",
      "6160\n",
      "6170\n",
      "6180\n",
      "6190\n",
      "6200\n",
      "6210\n",
      "6220\n",
      "6230\n",
      "6240\n",
      "6250\n",
      "6260\n"
     ]
    }
   ],
   "source": [
    "round_batches = batches[:len(batches)-1]\n",
    "all_acc_sim = []\n",
    "count = 0\n",
    "for i in round_batches:\n",
    "    for j in round_batches:\n",
    "        all_acc_sim.append(cosine_similarity(i, j, dense_output=True))\n",
    "    if count%10 == 0:\n",
    "        print(count)\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "21c3c388-829b-42b8-ab88-7938967e4a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.36765906,  0.99999964, -0.05642955,  0.05130933,  0.10695032,\n",
       "        0.07395042,  0.2655197 ,  0.1603888 ,  0.08726624,  0.17522533],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_acc_sim[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0707a472-c6ca-4b07-a266-6f20c14d9b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

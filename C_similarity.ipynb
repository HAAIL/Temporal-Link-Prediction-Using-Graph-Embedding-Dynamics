{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f4beb6-ac69-4fc0-8616-42604c7a232d",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc8240-611f-409e-be3c-adbcccee8512",
   "metadata": {},
   "source": [
    "### Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a1416a-0f4c-462d-b018-f59d09d96380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import random\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pickle5 as pickle\n",
    "from sklearn.svm import SVC\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39dfe50-0ef1-4a03-8f46-ec0759376197",
   "metadata": {},
   "source": [
    "### Step 2: Loading Embedded Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36356696-acd5-422d-9022-6fceeb95c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load('data/EMBEDDING/embeddeds_dim128_batchNumber200_length5_lookback1.npy')\n",
    "\n",
    "# We will predict 2019 collaborations based on 2018 and 2017 (these data is based on previous years, so prediction is based on\n",
    "# all previous years 2015, 2016, 2017, and 2018)\n",
    "embed2018 = embeddings[2]\n",
    "embed2017 = embeddings[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34477960-836d-4b51-acee-bab8ca5f6ae7",
   "metadata": {},
   "source": [
    "### Step 3: Sorted List of all Authors to have the same order in all Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9e96661-0361-40ba-be53-244db10ec708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To have sorted embedding in Output\n",
    "def node_sorter(graph):\n",
    "    H = nx.Graph()\n",
    "    new_nodes = sorted(graph.nodes(data=True))\n",
    "    H.add_nodes_from(new_nodes)\n",
    "    H.add_edges_from(graph.edges(data=True))\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5092bd83-bef4-4951-90b1-e7a80eba2863",
   "metadata": {},
   "source": [
    "### Step 4: Embedded Locations for 2017 and 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36a61fe6-ec8d-4ed9-a7de-61457f9540f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes in all these graphs are their intersection, so nose_set is the same for all years\n",
    "\n",
    "graph_2019 = nx.read_pajek('data/Graphs/pajek_graph19.net')\n",
    "SortedNodeG2019 = node_sorter(graph_2019)\n",
    "node_emb_dict_2018 = {list(SortedNodeG2019.nodes())[i] : embed2018[i] for i in range(len(SortedNodeG2019.nodes()))}\n",
    "node_emb_dict_2017 = {list(SortedNodeG2019.nodes())[i] : embed2017[i] for i in range(len(SortedNodeG2019.nodes()))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0814c13-eb2e-4d73-9d8b-37cbff5c74bc",
   "metadata": {},
   "source": [
    "### Step 5: Get Authors' names as Key for Embedded Locations Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8484493d-a7be-4236-8457-09897446d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_emb_dict18 = list(node_emb_dict_2018)\n",
    "nodes_num = len(node_emb_dict18)\n",
    "names = []\n",
    "for i in range(nodes_num):\n",
    "    names.append(node_emb_dict18[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be37e42a-efbb-4d06-b92b-88b57b7b0931",
   "metadata": {},
   "source": [
    "### Step 6: Computing (Predicting) Future Locations (2019) using 2017, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebb479ed-60c0-4ab8-aa2b-b445e3e9eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_velbased_loc = []\n",
    "for i in range(nodes_num):\n",
    "     all_velbased_loc.append(2*node_emb_dict_2018[names[i]] - node_emb_dict_2017[names[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afa0d2d-e2e3-4a0b-90d4-6ca14606ef0c",
   "metadata": {},
   "source": [
    "### Step 6: Partitioning Data to Handle Heavy Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e1db389-71aa-42b1-a878-8348d4373009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ww, hh = nodes_num, nodes_num\n",
    "#batch = [[0 for x in range(ww)] for y in range(hh)]\n",
    "batch_ = []\n",
    "strt = 0\n",
    "stp = 1000\n",
    "end_ = 1000\n",
    "num_batch = int(nodes_num/1000) + 1\n",
    "for i in range(num_batch):\n",
    "    #batch[i][:] = all_velbased_loc[strt:end_]\n",
    "    batch_.append(all_velbased_loc[strt:end_])\n",
    "    strt = end_\n",
    "    end_ = end_ + stp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf1cda-6cce-4daa-ad9b-ab590ea50555",
   "metadata": {},
   "source": [
    "### Step 7: Computing Cosine Similarity between each pair of Authors using their 2019 Predicted Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d05f92-8ec3-439a-a181-26ebfde4ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list containing h lists, each of w items, all set to 0\n",
    "w, h = nodes_num, nodes_num\n",
    "Matrix = [[0 for x in range(w)] for y in range(h)]\n",
    "\n",
    "c = 0\n",
    "\n",
    "for i in range(num_batch):\n",
    "    for j in range(1000):\n",
    "        for k in range(num_batch):\n",
    "            for l in range(1000):\n",
    "                a = batch_[i][k].reshape(-1, 1)\n",
    "                b = batch_[j][l].reshape(-1, 1)\n",
    "                temp = cosine_similarity(a, b)\n",
    "                row = int(c/nodes_num)\n",
    "                hight = c%nodes_num\n",
    "                Matrix[row][hight]\n",
    "                c = c + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f571852-4e52-4124-9812-6e9d66268790",
   "metadata": {},
   "source": [
    "### Save 2019 batched locations, so you can skip steps:1-6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "626fa1f8-65a8-47ed-8bb4-8cfa92be9956",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_batch):\n",
    "    with open(\"batch_\" + str(i), \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(batch_[i], fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0cb79-ded1-4cc0-b68d-d761a03637b6",
   "metadata": {},
   "source": [
    "### Step 8: load data, comput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04306acf-8113-4cf7-b944-8097d7407bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_batch_ = []\n",
    "for i in range(num_batch):\n",
    "    with open(\"Data_/batch_\"+str(i), \"rb\") as fp:\n",
    "        loaded_batch_.append(pickle.load(fp))\n",
    "        \n",
    "batch_ = loaded_batch_\n",
    "\n",
    "# Creates a list containing h lists, each of w items, all set to 0\n",
    "w, h = nodes_num, nodes_num\n",
    "Matrix = [[0 for x in range(w)] for y in range(h)]\n",
    "\n",
    "c = 0\n",
    "\n",
    "for i in range(num_batch):\n",
    "    for j in range(1000):\n",
    "        for k in range(num_batch):\n",
    "            for l in range(1000):\n",
    "                a = batch_[i][k].reshape(-1, 1)\n",
    "                b = batch_[j][l].reshape(-1, 1)\n",
    "                temp = cosine_similarity(a, b)\n",
    "                row = int(c/nodes_num)\n",
    "                hight = c%nodes_num\n",
    "                Matrix[row][hight]\n",
    "                c = c + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
